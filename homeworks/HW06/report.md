# HW06 – Report

> Файл: `homeworks/HW06/report.md`

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-01.csv`
- Размер: 12_000 строк, 30 столбцов.
- Целевая переменная: `target`(бинар. классификация), доли классов (0 ~ 68 %, 1 ~ 32 %).
- Признаки: исключительно числовые (float / int).

## 2. Protocol

- Разбиение: 80% train / 20% test (`test_size=0.2`, `random_state=42`).
- Подбор: кросс-валидация на 5 фолдах (cv=5). Оптимизировалась метрика f1 score.
- Метрики: Accuracy, F1, ROC-AUC.
- Почему они?: Accuracy дает общую картину, F1 важен для оценки качества классификации при возможных перекосах, а ROC-AUC оценивает способность модели ранжировать объекты по вероятности принадлежности к классу.

## 3. Models

В работе сравнивались следующие модели:

- DummyClassifier: baseline со стратегией `most_frequent`.
- LogisticRegression: линейный baseline (`L2-регуляризация`).
- DecisionTreeClassifier: контроль сложности через `max_depth` [3, 5, 8, 12] и `min_samples_leaf` [1, 5, 10, 20].
- RandomForestClassifier: ансамбль с подбором `model__max_features`: ['sqrt', 'log2'], `model__min_samples_leaf`: [2, 5].
- GradientBoostingClassifier: бустинг с подбором `model__learning_rate`: [0.05, 0.1], `model__n_estimators`: [100], `model__max_depth`: [3, 5].

## 4. Results

| Модель | Accuracy | F1-Score | ROC-AUC |
| --- | --- | --- | --- |
| Dummy Classifier | 0.6800 | 0.0000 | не счит. |
| LogisticRegression | 0.8300 | 0.7100 | не счит. |
| DecisionTree | 0.8717 | 0.7944 | 0.8845 |
| **RandomForest** | **0.9246** | **0.8775** | **0.9648** |
| GradientBoosting | 0.9192 | 0.8686 | 0.9640 |

**Победитель**: `RandomForest`. Модель показала лучший результат по ROC-AUC. Это объясняется устойчивостью случайного леса к шуму и эффективным усреднением предсказаний множества деревьев.

## 5. Analysis

- Устойчивость: проверка модели при вариации `random_state` (5 прогонов) показала высокую стабильность результатов RandomForest: стандартное отклонение метрик составило менее `±0.015`. В отличие от одиночного дерева, ансамбль нивелирует случайные флуктуации в данных, что подтверждает его надежность для продуктового использования.
- Ошибки: на основе анализа Confusion Matrix и ROC-кривой, модель демонстрирует сбалансированные показатели. Зафиксировано небольшое превалирование ошибок типа `False Positive` над `False Negative`. Это указывает на умеренно консервативную стратегию классификатора, который сохраняет высокое значение Precision, минимизируя пропуск целевых событий..
- Интерпретация: согласно **Permutation Importance**, ключевыми признаками являются `num19` и `num18`. Их перемешивание снижает F1 на 11-14%. Большинство остальных признаков имеют важность менее 2%, что указывает на наличие в данных «шумных» переменных, которые ансамбль успешно отфильтровал.

## 6. Conclusion

1. **Ансамбли эффективнее**: RandomForest и Boosting значительно превосходят одиночное дерево за счет снижения разброса (variance) и смещения (bias).
2. **Контроль сложности критичен**: Ограничение глубины (`max_depth`) и количества листьев — единственный способ спасти дерево от переобучения ("зубрежки" трейна).
3. **Честный протокол**: Использование `GridSearchCV` вместе с `Pipeline` гарантирует, что мы не «подглядываем» в тестовые данные при масштабировании или подборе параметров.
4. **Важность признаков**: Permutation Importance — более надежный метод, чем встроенный `feature_importances_`, так как он оценивает реальное падение качества на отложенной выборке.

---
Я где - то в конце осознал, что, наверное, ROC AUC И confusion матрицы
стоило посчитать и для baseline моделей.